{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
      ],
      "metadata": {
        "id": "j8eBj2zfpXR5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "W2ctvg2EtSeK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BRjMAVFRkurY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import ViTForImageClassification, DeiTForImageClassification, ViTFeatureExtractor, DeiTFeatureExtractor\n",
        "from transformers import AdamW\n",
        "from transformers import get_scheduler\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from PIL import Image\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4SZKJD3fliLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "000d024b-9600-407f-8e9a-56e636ae7c7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/My Drive/slash data'"
      ],
      "metadata": {
        "id": "vMTmBRiUlnUF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "image_size = (150, 150)\n",
        "num_classes = 8\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "Fs69EvQhlqGY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "ySywpFgQlud0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66111253-c8c0-4151-d0ea-0258458ace99"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2088 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1523 image from the app and 565 scraped from internet"
      ],
      "metadata": {
        "id": "hQG5gZbLDerb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN archticture approach"
      ],
      "metadata": {
        "id": "9ESfxFU2mXLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "tOiaXwUfmVRW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dUsG8ZULmmCl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oTpEbn2akIKl",
        "outputId": "f1e64866-72a1-4642-c891-e0ac856a7779"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "        train_generator,\n",
        "        epochs=epochs,\n",
        "        steps_per_epoch=train_generator.samples // batch_size,\n",
        "        verbose=1\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKtind_epMgt",
        "outputId": "9f523fda-9c45-45dd-c8e2-25b8a79dabfc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 735s 45s/step - loss: 2.4583 - accuracy: 0.1862\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 1.9776 - accuracy: 0.2444\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 50s 3s/step - loss: 1.8179 - accuracy: 0.3296\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 48s 3s/step - loss: 1.7042 - accuracy: 0.3837\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 48s 3s/step - loss: 1.6467 - accuracy: 0.4056\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 50s 3s/step - loss: 1.5333 - accuracy: 0.4526\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 1.5048 - accuracy: 0.4679\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 1.4158 - accuracy: 0.4980\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 48s 3s/step - loss: 1.3572 - accuracy: 0.5133\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 48s 3s/step - loss: 1.2959 - accuracy: 0.5327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(train_generator)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "05dAhTCamrbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43bf5e60-60e7-486d-c11f-e0aebe1e6465"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 1/17 [>.............................] - ETA: 45s - loss: 1.3105 - accuracy: 0.5312"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 51s 3s/step - loss: 1.2433 - accuracy: 0.5508\n",
            "Test Accuracy: 0.5507662892341614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Residual Archticture"
      ],
      "metadata": {
        "id": "7muFK2NPnK7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, ReLU, add, GlobalAveragePooling2D, Dense\n",
        "def residual_block(input_layer, filters, kernel_size=(3, 3), strides=(1, 1), activation='relu'):\n",
        "    x = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(input_layer)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    if activation is not None:\n",
        "        x = add([input_layer, x])\n",
        "        x = ReLU()(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "BjK7K3cQnQDY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, MaxPooling2D, GlobalAveragePooling2D, Dense, Add\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def residual_block(x, filters, strides=(1, 1)):\n",
        "    shortcut = x\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    if strides != (1, 1) or shortcut.shape[-1] != filters:\n",
        "        shortcut = Conv2D(filters, kernel_size=(1, 1), strides=strides, padding='same')(shortcut)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "# ResNet architecture\n",
        "inputs = Input(shape=(image_size[0], image_size[1], 3))\n",
        "x = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = ReLU()(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "# Residual blocks\n",
        "x = residual_block(x, 64)\n",
        "x = residual_block(x, 64)\n",
        "x = residual_block(x, 64)\n",
        "\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "x = residual_block(x, 128, strides=(2, 2))\n",
        "x = residual_block(x, 128)\n",
        "x = residual_block(x, 128)\n",
        "x = residual_block(x, 128)\n",
        "\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "x = residual_block(x, 256, strides=(2, 2))\n",
        "x = residual_block(x, 256)\n",
        "x = residual_block(x, 256)\n",
        "x = residual_block(x, 256)\n",
        "x = residual_block(x, 256)\n",
        "x = residual_block(x, 256)\n",
        "\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "x = residual_block(x, 512, strides=(2, 2))\n",
        "x = residual_block(x, 512)\n",
        "x = residual_block(x, 512)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "U8xSUV-7naI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1dcf2c4-4e89-453c-a428-a82207bd9a93"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 150, 150, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 75, 75, 64)           9472      ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 75, 75, 64)           256       ['conv2d_15[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)              (None, 75, 75, 64)           0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPoolin  (None, 38, 38, 64)           0         ['re_lu_8[0][0]']             \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 38, 38, 64)           36928     ['max_pooling2d_8[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 38, 38, 64)           256       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)              (None, 38, 38, 64)           0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 38, 38, 64)           36928     ['re_lu_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 38, 38, 64)           256       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 38, 38, 64)           0         ['batch_normalization_11[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'max_pooling2d_8[0][0]']     \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)             (None, 38, 38, 64)           0         ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 38, 38, 64)           36928     ['re_lu_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 38, 38, 64)           256       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)             (None, 38, 38, 64)           0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 38, 38, 64)           36928     ['re_lu_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 38, 38, 64)           256       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 38, 38, 64)           0         ['batch_normalization_13[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_10[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)             (None, 38, 38, 64)           0         ['add_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 38, 38, 64)           36928     ['re_lu_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 38, 38, 64)           256       ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)             (None, 38, 38, 64)           0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 38, 38, 64)           36928     ['re_lu_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 38, 38, 64)           256       ['conv2d_21[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 38, 38, 64)           0         ['batch_normalization_15[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_12[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)             (None, 38, 38, 64)           0         ['add_6[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPoolin  (None, 19, 19, 64)           0         ['re_lu_14[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 10, 10, 128)          73856     ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 10, 10, 128)          512       ['conv2d_22[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)             (None, 10, 10, 128)          0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 10, 10, 128)          147584    ['re_lu_15[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 10, 10, 128)          8320      ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 10, 10, 128)          512       ['conv2d_23[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 10, 10, 128)          512       ['conv2d_24[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 10, 10, 128)          0         ['batch_normalization_17[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)             (None, 10, 10, 128)          0         ['add_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 10, 10, 128)          147584    ['re_lu_16[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 10, 10, 128)          512       ['conv2d_25[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)             (None, 10, 10, 128)          0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 10, 10, 128)          147584    ['re_lu_17[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 10, 10, 128)          512       ['conv2d_26[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 10, 10, 128)          0         ['batch_normalization_20[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_16[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)             (None, 10, 10, 128)          0         ['add_8[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 10, 10, 128)          147584    ['re_lu_18[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 10, 10, 128)          512       ['conv2d_27[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)             (None, 10, 10, 128)          0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 10, 10, 128)          147584    ['re_lu_19[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 10, 10, 128)          512       ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_9 (Add)                 (None, 10, 10, 128)          0         ['batch_normalization_22[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_18[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)             (None, 10, 10, 128)          0         ['add_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 10, 10, 128)          147584    ['re_lu_20[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 10, 10, 128)          512       ['conv2d_29[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)             (None, 10, 10, 128)          0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 10, 10, 128)          147584    ['re_lu_21[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 10, 10, 128)          512       ['conv2d_30[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_10 (Add)                (None, 10, 10, 128)          0         ['batch_normalization_24[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_20[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_22 (ReLU)             (None, 10, 10, 128)          0         ['add_10[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooli  (None, 5, 5, 128)            0         ['re_lu_22[0][0]']            \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 3, 3, 256)            295168    ['max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 3, 3, 256)            1024      ['conv2d_31[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_23 (ReLU)             (None, 3, 3, 256)            0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 3, 3, 256)            590080    ['re_lu_23[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 3, 3, 256)            33024     ['max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 3, 3, 256)            1024      ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 3, 3, 256)            1024      ['conv2d_33[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_11 (Add)                (None, 3, 3, 256)            0         ['batch_normalization_26[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_24 (ReLU)             (None, 3, 3, 256)            0         ['add_11[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 3, 3, 256)            590080    ['re_lu_24[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 3, 3, 256)            1024      ['conv2d_34[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_25 (ReLU)             (None, 3, 3, 256)            0         ['batch_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 3, 3, 256)            590080    ['re_lu_25[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_29 (Ba  (None, 3, 3, 256)            1024      ['conv2d_35[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_12 (Add)                (None, 3, 3, 256)            0         ['batch_normalization_29[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_24[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_26 (ReLU)             (None, 3, 3, 256)            0         ['add_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 3, 3, 256)            590080    ['re_lu_26[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_30 (Ba  (None, 3, 3, 256)            1024      ['conv2d_36[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_27 (ReLU)             (None, 3, 3, 256)            0         ['batch_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 3, 3, 256)            590080    ['re_lu_27[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_31 (Ba  (None, 3, 3, 256)            1024      ['conv2d_37[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_13 (Add)                (None, 3, 3, 256)            0         ['batch_normalization_31[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_26[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_28 (ReLU)             (None, 3, 3, 256)            0         ['add_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)          (None, 3, 3, 256)            590080    ['re_lu_28[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (Ba  (None, 3, 3, 256)            1024      ['conv2d_38[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_29 (ReLU)             (None, 3, 3, 256)            0         ['batch_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)          (None, 3, 3, 256)            590080    ['re_lu_29[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 3, 3, 256)            1024      ['conv2d_39[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_14 (Add)                (None, 3, 3, 256)            0         ['batch_normalization_33[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_28[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_30 (ReLU)             (None, 3, 3, 256)            0         ['add_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)          (None, 3, 3, 256)            590080    ['re_lu_30[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 3, 3, 256)            1024      ['conv2d_40[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_31 (ReLU)             (None, 3, 3, 256)            0         ['batch_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)          (None, 3, 3, 256)            590080    ['re_lu_31[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 3, 3, 256)            1024      ['conv2d_41[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_15 (Add)                (None, 3, 3, 256)            0         ['batch_normalization_35[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_30[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_32 (ReLU)             (None, 3, 3, 256)            0         ['add_15[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)          (None, 3, 3, 256)            590080    ['re_lu_32[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_36 (Ba  (None, 3, 3, 256)            1024      ['conv2d_42[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_33 (ReLU)             (None, 3, 3, 256)            0         ['batch_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)          (None, 3, 3, 256)            590080    ['re_lu_33[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_37 (Ba  (None, 3, 3, 256)            1024      ['conv2d_43[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_16 (Add)                (None, 3, 3, 256)            0         ['batch_normalization_37[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_32[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_34 (ReLU)             (None, 3, 3, 256)            0         ['add_16[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooli  (None, 2, 2, 256)            0         ['re_lu_34[0][0]']            \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)          (None, 1, 1, 512)            1180160   ['max_pooling2d_11[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 1, 1, 512)            2048      ['conv2d_44[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_35 (ReLU)             (None, 1, 1, 512)            0         ['batch_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)          (None, 1, 1, 512)            2359808   ['re_lu_35[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)          (None, 1, 1, 512)            131584    ['max_pooling2d_11[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 1, 1, 512)            2048      ['conv2d_45[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 1, 1, 512)            2048      ['conv2d_46[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_17 (Add)                (None, 1, 1, 512)            0         ['batch_normalization_39[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_36 (ReLU)             (None, 1, 1, 512)            0         ['add_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)          (None, 1, 1, 512)            2359808   ['re_lu_36[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 1, 1, 512)            2048      ['conv2d_47[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_37 (ReLU)             (None, 1, 1, 512)            0         ['batch_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)          (None, 1, 1, 512)            2359808   ['re_lu_37[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_42 (Ba  (None, 1, 1, 512)            2048      ['conv2d_48[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_18 (Add)                (None, 1, 1, 512)            0         ['batch_normalization_42[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_36[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_38 (ReLU)             (None, 1, 1, 512)            0         ['add_18[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)          (None, 1, 1, 512)            2359808   ['re_lu_38[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_43 (Ba  (None, 1, 1, 512)            2048      ['conv2d_49[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_39 (ReLU)             (None, 1, 1, 512)            0         ['batch_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)          (None, 1, 1, 512)            2359808   ['re_lu_39[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (Ba  (None, 1, 1, 512)            2048      ['conv2d_50[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_19 (Add)                (None, 1, 1, 512)            0         ['batch_normalization_44[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_38[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_40 (ReLU)             (None, 1, 1, 512)            0         ['add_19[0][0]']              \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 512)                  0         ['re_lu_40[0][0]']            \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 8)                    4104      ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21314312 (81.31 MB)\n",
            "Trainable params: 21297288 (81.24 MB)\n",
            "Non-trainable params: 17024 (66.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "0zywwfdonbz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e6bfdf-9abf-44d5-c26c-dd85222f4082"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 132s 3s/step - loss: 2.4591 - accuracy: 0.3393\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 50s 3s/step - loss: 1.6204 - accuracy: 0.4230\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 47s 3s/step - loss: 1.4637 - accuracy: 0.4735\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 1.3528 - accuracy: 0.5209\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 48s 3s/step - loss: 1.3171 - accuracy: 0.5219\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 46s 3s/step - loss: 1.2284 - accuracy: 0.5510\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 48s 3s/step - loss: 1.1407 - accuracy: 0.5934\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 48s 3s/step - loss: 1.1719 - accuracy: 0.5704\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 50s 3s/step - loss: 1.0248 - accuracy: 0.6357\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 48s 3s/step - loss: 0.9464 - accuracy: 0.6694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(train_generator)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "h_ytuI6undwk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c979a6b0-eb22-4853-9754-2f4221dddf8b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 50s 3s/step - loss: 3.0135 - accuracy: 0.1671\n",
            "Test Accuracy: 0.16714559495449066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tune VGG16"
      ],
      "metadata": {
        "id": "Y1TJSDjzp1IX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))"
      ],
      "metadata": {
        "id": "erHopDdbp6ww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "177954b3-c079-48a7-e6b2-50886cd82741"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze convolutional layers\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, MaxPooling2D, GlobalAveragePooling2D, Dense, Add, Dropout\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "uJfhvNvsp92R"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7aHd2WSSp4Nw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "mvqHLb1KqC5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ab6a5b-47b3-43db-cb29-e3657f5f2978"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 58s 3s/step - loss: 2.5205 - accuracy: 0.3230\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 1.3719 - accuracy: 0.5056\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 1.1864 - accuracy: 0.5740\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 48s 3s/step - loss: 1.0361 - accuracy: 0.6281\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 1.0001 - accuracy: 0.6474\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 0.9530 - accuracy: 0.6827\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 0.8807 - accuracy: 0.6929\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 0.8463 - accuracy: 0.7061\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 0.8188 - accuracy: 0.7163\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 0.8099 - accuracy: 0.7250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(train_generator)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "z217JV8oqE7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a5352b-755c-43e3-c569-39ced7dd05fb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 52s 3s/step - loss: 0.6316 - accuracy: 0.7998\n",
            "Test Accuracy: 0.7998084425926208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tune Resnet50"
      ],
      "metadata": {
        "id": "ZcqtBWRiqTsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained ResNet50 model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))"
      ],
      "metadata": {
        "id": "Ifynz5Fbqb7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ffaf02-599a-4442-8d99-4673ee290d40"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the layers except the last few layers\n",
        "for layer in base_model.layers[:-10]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "M-V0G8-gqdrQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "_GTRq6ewqgO7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bptcn3QZqiGj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "mQ3pfOXnqlY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57cfd9a-2954-4315-aab1-396180270509"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 56s 3s/step - loss: 1.8851 - accuracy: 0.2980\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 48s 3s/step - loss: 1.6802 - accuracy: 0.3531\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 1.5629 - accuracy: 0.4204\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 1.5200 - accuracy: 0.4357\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 50s 3s/step - loss: 1.4879 - accuracy: 0.4327\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 1.4357 - accuracy: 0.4786\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 47s 3s/step - loss: 1.4029 - accuracy: 0.4745\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 1.4250 - accuracy: 0.4745\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 1.3915 - accuracy: 0.4867\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 47s 3s/step - loss: 1.3409 - accuracy: 0.4949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(train_generator)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "9MT9XgZ-qnzi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d29042f3-6433-426d-8a71-812400d5486c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 54s 3s/step - loss: 1.7810 - accuracy: 0.3103\n",
            "Test Accuracy: 0.3103448152542114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tune Inception V3"
      ],
      "metadata": {
        "id": "N5SUupTiqy_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained InceptionV3 model\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))"
      ],
      "metadata": {
        "id": "q0zR6hNPq6Lj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61fb9c18-98f1-44db-91a0-20dd04bafc62"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[:-10]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "cyZmrSloq7k5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "DyngR4qgq9kZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "B3Oo7QQqrAvH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "2ruHaOOerC1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65b07e80-6904-4869-e595-b07a63fc7bf1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 58s 3s/step - loss: 3.4041 - accuracy: 0.3643\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 50s 3s/step - loss: 1.2757 - accuracy: 0.5522\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 50s 3s/step - loss: 0.9965 - accuracy: 0.6551\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 0.8773 - accuracy: 0.6806\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 48s 3s/step - loss: 0.7801 - accuracy: 0.7250\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 50s 3s/step - loss: 0.8132 - accuracy: 0.7128\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 48s 3s/step - loss: 0.7028 - accuracy: 0.7541\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 49s 3s/step - loss: 0.6693 - accuracy: 0.7699\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 48s 3s/step - loss: 0.6527 - accuracy: 0.7668\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 47s 3s/step - loss: 0.6406 - accuracy: 0.7719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(train_generator)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "Bh50uJmurFAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df283a38-6291-47a7-ee60-e3fb3518224d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 54s 3s/step - loss: 0.6135 - accuracy: 0.7792\n",
            "Test Accuracy: 0.7792145609855652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "inception has best generalization and best inferance"
      ],
      "metadata": {
        "id": "4mxFyUeJAZZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/content/drive/My Drive/slash data/my_model_weights.h5')"
      ],
      "metadata": {
        "id": "9OwkZVg5As_l"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vision Transformers based (vit model)"
      ],
      "metadata": {
        "id": "QJbtTzVYrjFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "data_path = '/content/drive/My Drive/slash data'\n",
        "class_folders = os.listdir(data_path)\n",
        "class_labels = {label: index for index, label in enumerate(class_folders)}\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "for class_folder in class_folders:\n",
        "    class_path = os.path.join(data_path, class_folder)\n",
        "    for img_file in os.listdir(class_path):\n",
        "        img_path = os.path.join(class_path, img_file)\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"Image not found: {img_path}\")\n",
        "        else:\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                print(f\"Error loading image: {img_path}\")\n",
        "            else:\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                img = cv2.resize(img, (224, 224))\n",
        "                images.append(img)\n",
        "                labels.append(class_labels[class_folder])\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjKxjcsOHd6E",
        "outputId": "8e5ae8df-a3d8-415a-f2e9-27a490c43172"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image: /content/drive/My Drive/slash data/Artifacts/vector.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Artifacts/vector13.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Artifacts/vector2.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Artifacts/vector4.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Artifacts/vector12.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Artifacts/vector7.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Artifacts/vector3.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Artifacts/vector5.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Artifacts/vector10.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Artifacts/vector11.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Artifacts/vector6.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Artifacts/vector8.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Artifacts/vector9.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Nutrition/vector8.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Nutrition/vector2.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Nutrition/vector7.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Nutrition/vector4.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Nutrition/vector.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Nutrition/vector5.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Nutrition/vector12.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Nutrition/vector6.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Nutrition/vector3.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Nutrition/vector13.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Nutrition/vector9.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Nutrition/vector10.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Nutrition/vector11.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Accessories/vector6.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Accessories/vector14.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Accessories/vector2.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Accessories/vector5.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Accessories/vector.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Accessories/vector12.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Accessories/vector11.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Accessories/vector4.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Accessories/vector9.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Accessories/vector10.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Accessories/vector7.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Accessories/vector3.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Accessories/vector8.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Accessories/vector13.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Beauty/vector4.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Beauty/vector3.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Beauty/vector11.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Beauty/vector.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Beauty/vector10.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Beauty/vector2.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Beauty/vector8.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Beauty/vector9.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Beauty/vector6.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Beauty/vector5.svg\n",
            "Error loading image: /content/drive/My Drive/slash data/Beauty/vector7.svg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize if required\n",
        "])\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = CustomDataset(X_train, y_train, transform=transform)\n",
        "test_dataset = CustomDataset(X_test, y_test, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "_4qsjk8qHZC7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained ViT model\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "\n",
        "num_classes = 8\n",
        "model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvnUj8FpHVIY",
        "outputId": "ef4a4b36-ac34-4ed1-8cdc-215c735f5802"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        logits = outputs.logits  # Extract logits from ImageClassifierOutput\n",
        "\n",
        "\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPBOQgFTHRlW",
        "outputId": "5f7b00d9-e20c-4f9a-c244-d4ad398b5c9b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.2984339373452323\n",
            "Epoch 2/10, Loss: 0.4001759106204623\n",
            "Epoch 3/10, Loss: 0.14325493120011829\n",
            "Epoch 4/10, Loss: 0.08113635962917691\n",
            "Epoch 5/10, Loss: 0.06111705150632631\n",
            "Epoch 6/10, Loss: 0.08401988205455599\n",
            "Epoch 7/10, Loss: 0.03091327017616658\n",
            "Epoch 8/10, Loss: 0.024479531372586887\n",
            "Epoch 9/10, Loss: 0.02159068722810064\n",
            "Epoch 10/10, Loss: 0.015464093287785847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.eval()\n",
        "\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "\n",
        "        predicted = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "accuracy = total_correct / total_samples\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr2cP6jXFR8q",
        "outputId": "0ecfc41c-8482-469d-d32d-7e8237c722ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9833333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "transformers based is the best model to save for deployment and thats make sense that it trained by google and trained on a huge data"
      ],
      "metadata": {
        "id": "M3WJXu5WIMdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_weights_path = 'model_weights.pth'\n",
        "\n",
        "# Save the model weights\n",
        "torch.save(model.state_dict(), model_weights_path)\n"
      ],
      "metadata": {
        "id": "Wa4iXMNGKbj3"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}